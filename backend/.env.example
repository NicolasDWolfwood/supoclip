# The model size of OpenAI Whisper (see https://github.com/openai/whisper#available-models-and-languages)
WHISPER_MODEL_SIZE=medium
WHISPER_DEVICE=auto
WHISPER_CHUNKING_ENABLED=true
WHISPER_CHUNK_DURATION_SECONDS=1200
WHISPER_CHUNK_OVERLAP_SECONDS=8

# Local host mapping (docker-compose reads these from root `.env`).
APP_HOST=localhost
FRONTEND_HOST_PORT=3000
BACKEND_HOST_PORT=8000
POSTGRES_HOST_PORT=5432
REDIS_HOST_PORT=6379
# Browser-facing URLs are derived from APP_HOST + *_HOST_PORT variables.
BETTER_AUTH_TRUSTED_ORIGINS=http://localhost:3000,http://127.0.0.1:3000

# Transcription provider:
# - local (default): run Whisper locally
# - assemblyai: use AssemblyAI API
TRANSCRIPTION_PROVIDER=local

# MediaPipe face detector model (used for face-aware vertical crop)
MEDIAPIPE_FACE_MODEL_PATH=./models/blaze_face_short_range.tflite
MEDIAPIPE_FACE_MODEL_URL=https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite
MEDIAPIPE_FACE_MODEL_SHA256=b4578f35940bf5a1a655214a1cce5cab13eba73c1297cd78e1a04c2380b0152f
MEDIAPIPE_FACE_MODEL_AUTO_DOWNLOAD=true

# LLM Providers
OPENAI_API_KEY=
GOOGLE_API_KEY=
ANTHROPIC_API_KEY=
# z.ai uses Coding API endpoint: https://api.z.ai/api/coding/paas/v4
# Optional: users can also save subscription/metered z.ai keys in Settings;
# this env key remains a backend fallback.
ZAI_API_KEY=
ADMIN_API_KEY=

# The AI Model to use throughout the app
LLM=openai:gpt-5-mini

# Good for speed optimizations
COMPOSE_BAKE=true

# DB
POSTGRES_DB=supoclip
POSTGRES_USER=supoclip
POSTGRES_PASSWORD=supoclip_password

ASSEMBLY_AI_API_KEY=

# Worker concurrency (local transcription is CPU-heavy)
WORKER_MAX_JOBS=2
WORKER_JOB_TIMEOUT_SECONDS=21600

# Queue names for transcription routing
ARQ_QUEUE_NAME_LOCAL=arq:queue:local
ARQ_QUEUE_NAME_ASSEMBLY=arq:queue:assembly

# Optional second worker (compose profile: multi-worker)
WORKER2_MAX_JOBS=1
WORKER2_WHISPER_DEVICE=auto
ENABLE_MULTI_WORKER=false

# Host bind-mount location for Whisper model cache (docker-compose)
WHISPER_CACHE_HOST_DIR=./backend/.cache/whisper

# Optional GPU request override for second worker in compose profile
DOCKER_GPU_REQUEST_WORKER2=all

# Optional GPU request override for dedicated AssemblyAI worker
DOCKER_GPU_REQUEST_WORKER_ASSEMBLY=all

# Optional encryption secret for user-stored API keys
SECRET_ENCRYPTION_KEY=
